{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyunseo.lee/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIDataset(Dataset):\n",
    "    def __init__(self, data_dir, csv_file, transform=None, skin_threshold=35):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (str): file directory with all the DDI images.\n",
    "            csv_file (str): path to the ddi_metadata.csv file with annotations.\n",
    "            transform (callable): transform applied on a sample.\n",
    "            skin_threshold (int): threshold to decide light or dark skin tone.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.skin_threshold = skin_threshold\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.data_dir, row[\"DDI_file\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        skin_label = \"light\" if row[\"skin_tone\"] < self.skin_threshold else \"dark\"\n",
    "        malignant = row[\"malignant\"]\n",
    "        \n",
    "        return {\"image\": image, \n",
    "                \"skin_tone\": skin_label, \n",
    "                \"malignant\": malignant}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAMDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_dir (str): path to folder containing HAM10000 images.\n",
    "        csv_file (str): path to HAM10000_metadata.csv.\n",
    "        transform (callable, optional): torchvision transforms to apply.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, csv_file, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        df = pd.read_csv(csv_file)\n",
    "        df[\"image_id\"] = df[\"image_id\"].astype(str)\n",
    "        self.meta = df.set_index(\"image_id\")\n",
    "        \n",
    "        self.image_files = [\n",
    "            fname for fname in os.listdir(data_dir)\n",
    "            if os.path.splitext(fname)[1].lower() in {\".jpg\", \".jpeg\", \".png\"}\n",
    "        ]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.image_files[idx]\n",
    "        image_id, _ = os.path.splitext(fname)\n",
    "        \n",
    "        row = self.meta.loc[image_id]\n",
    "        lesion_id = row[\"lesion_id\"]\n",
    "        dx = row[\"dx\"].strip().lower()\n",
    "        malignant = (dx == \"melanoma\")\n",
    "        \n",
    "        img_path = os.path.join(self.data_dir, fname)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"lesion_id\": lesion_id,\n",
    "            \"malignant\": malignant\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657\n",
      "10016\n"
     ]
    }
   ],
   "source": [
    "# load ddi and HAM10000 data\n",
    "ddi_data_dir = \"../data/ddi_cropped\"\n",
    "os.listdir(ddi_data_dir)\n",
    "print(len(os.listdir(ddi_data_dir)))\n",
    "\n",
    "ham_data_dir = \"../data/HAM10000\"\n",
    "os.listdir(ham_data_dir)\n",
    "print(len(os.listdir(ham_data_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddi description file:\n",
      "    Unnamed: 0  DDI_ID    DDI_file  skin_tone  malignant  \\\n",
      "0           0       1  000001.png         56       True   \n",
      "1           1       2  000002.png         56       True   \n",
      "2           2       3  000003.png         56       True   \n",
      "3           3       4  000004.png         56       True   \n",
      "4           4       5  000005.png         12       True   \n",
      "\n",
      "                           disease  \n",
      "0                 melanoma-in-situ  \n",
      "1                 melanoma-in-situ  \n",
      "2                mycosis-fungoides  \n",
      "3  squamous-cell-carcinoma-in-situ  \n",
      "4             basal-cell-carcinoma  \n",
      "___________________________________\n",
      "ham description file:\n",
      "      lesion_id      image_id   dx dx_type   age   sex localization\n",
      "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
      "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
      "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
      "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
      "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n"
     ]
    }
   ],
   "source": [
    "# label the data according to their information\n",
    "ddi_label_file = os.path.join(ddi_data_dir, \"ddi_metadata.csv\")\n",
    "ham_label_file = os.path.join(ham_data_dir, \"HAM10000_metadata.csv\")\n",
    "df_ddi = pd.read_csv(ddi_label_file)\n",
    "df_ham = pd.read_csv(ham_label_file)\n",
    "print(\"ddi description file:\\n\", df_ddi.head())\n",
    "print(\"___________________________________\")\n",
    "print(\"ham description file:\\n\", df_ham.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train images for ddi: 393\n",
      "number of val images for ddi: 131\n",
      "number of test images for ddi: 132\n",
      "------------------------------\n",
      "number of train images for ham: 6009\n",
      "number of val images for ham: 2003\n",
      "number of test images for ham: 2003\n"
     ]
    }
   ],
   "source": [
    "# data splitting\n",
    "# train: 60%, val: 20%, test: 20%\n",
    "def split_data(data_dir, train_ratio=0.6, val_ratio=0.2):\n",
    "    all_files = os.listdir(data_dir)\n",
    "    num_files = len(all_files)\n",
    "    \n",
    "    train_size = int(num_files * train_ratio)\n",
    "    val_size = int(num_files * val_ratio)\n",
    "    \n",
    "    train_files = all_files[:train_size]\n",
    "    val_files = all_files[train_size:train_size + val_size]\n",
    "    test_files = all_files[train_size + val_size:]\n",
    "    \n",
    "    return train_files, val_files, test_files\n",
    "\n",
    "train_files_ddi, val_files_ddi, test_files_ddi = split_data(ddi_data_dir)\n",
    "train_files_ham, val_files_ham, test_files_ham = split_data(ham_data_dir)\n",
    "\n",
    "print(\"number of train images for ddi:\", len(train_files_ddi))\n",
    "print(\"number of val images for ddi:\", len(val_files_ddi))\n",
    "print(\"number of test images for ddi:\", len(test_files_ddi))\n",
    "print(\"------------------------------\")\n",
    "print(\"number of train images for ham:\", len(train_files_ham))\n",
    "print(\"number of val images for ham:\", len(val_files_ham))\n",
    "print(\"number of test images for ham:\", len(test_files_ham))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "    # Convert the tensor to a PIL image\n",
    "    image = transforms.ToPILImage()(image)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)), # Resizes (32,32) to (224,224)\n",
    "        # transforms.RandomCrop((220,220)), # Takes a random (32,32) crop\n",
    "        # transforms.ColorJitter(brightness=0.5), # Change brightness of image\n",
    "        transforms.RandomRotation(degrees=45), # Perhaps a random rotation from -45 to 45 degrees\n",
    "        # transforms.RandomHorizontalFlip(p=0.5), # Flips the image horizontally with probability 0.5\n",
    "        # transforms.RandomVerticalFlip(p=0.05), # Flips image vertically with probability 0.05\n",
    "        transforms.RandomGrayscale(p=0.2), # Converts to grayscale with probability 0.2\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizes between -1 and 1\n",
    "    ])\n",
    "    # Load the dataset\n",
    "    ddi_dataset = datasets.ImageFolder(ddi_data_dir, transform=transform)\n",
    "    ham_dataset = datasets.ImageFolder(ham_data_dir, transform=transform)\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(ddi_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(ham_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(ham_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # Display a sample image from the dataset\n",
    "    sample_image, _ = next(iter(train_loader))\n",
    "    display_image(sample_image[0])  # Display the first image in the batch\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformations\n",
    "# torch normalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

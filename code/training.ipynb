{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_loading'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_loading\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data \u001b[38;5;66;03m# Data.py\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcyclegan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Generator, Discriminator, adversarial_loss, cycle_loss, identity_loss\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_loading'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from data_loading import load_data # data_loading.py\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from cyclegan import Generator, Discriminator, adversarial_loss, cycle_loss, identity_loss\n",
    "# from cyclegan import cyclegan_model #depends on name of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "batch_size = 1\n",
    "train_loader, validation_loader, test_loader, classes, batch_size = load_data(batch_size)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.0002\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# version = 'v1'\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "'''\n",
    "X to Y: upsampling (encoder)\n",
    "Y to X: downsampling (decoder)\n",
    "'''\n",
    "generate_XtoY = Generator().to(device) #upsampling (encoder)\n",
    "generate_YtoX = Generator().to(device) #downsampling (decoder)\n",
    "Discriminator_X = Discriminator().to(device) #discriminator for X \n",
    "Discriminator_Y = Discriminator().to(device) #discriminator for Y\n",
    "\n",
    "# model = cyclegan_model(version=version).to(device)\n",
    "\n",
    "#call the loss functions\n",
    "adversarial_loss_func = adversarial_loss()  # Adversarial loss\n",
    "cycle_loss_func = cycle_loss()   # Cycle consistency loss\n",
    "identity_loss_func = identity_loss()   # Identity loss\n",
    "optimizer_for_generators = optim.Adam(\n",
    "    itertools.chain(generate_XtoY.parameters(), generate_YtoX.parameters()), lr=learning_rate, betas=(0.5, 0.999)\n",
    ")\n",
    "optimizer_discriminator_X = optim.Adam(Discriminator_X.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "optimizer_discriminator_Y = optim.Adam(Discriminator_Y.parameters(), lr=learning_rate, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train_cyclegan(train_loader, generate_XtoY, generate_YtoX, Discriminator_X, Discriminator_Y, device):\n",
    "    # model.train() # Model in training mode\n",
    "    generate_XtoY.train()\n",
    "    generate_YtoX.train()\n",
    "    Discriminator_X.train()\n",
    "    Discriminator_Y.train()\n",
    "\n",
    "    total_loss_generator = 0.0\n",
    "    total_loss_discriminator_X = 0.0\n",
    "    total_loss_discriminator_Y = 0.0\n",
    "\n",
    "    for batch_idx, (real_X, real_Y) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
    "        real_X, real_Y = real_X.to(device), real_Y.to(device)\n",
    "        # Train generators\n",
    "        optimizer_for_generators.zero_grad()\n",
    "\n",
    "        #forward pass\n",
    "        fake_Y = generate_XtoY(real_X)\n",
    "        fake_X = generate_YtoX(real_Y)\n",
    "        cycle_X = generate_YtoX(fake_Y)\n",
    "        cycle_Y = generate_XtoY(fake_X)\n",
    "\n",
    "        # Adversarial loss\n",
    "        loss_G_XtoY = adversarial_loss(Discriminator_Y(fake_Y), torch.ones_like(Discriminator_Y(fake_Y)))\n",
    "        loss_G_YtoX = adversarial_loss(Discriminator_X(fake_X), torch.ones_like(Discriminator_X(fake_X)))\n",
    "\n",
    "        # Cycle consistency loss \n",
    "        loss_cycle_X = cycle_loss_func(real_X, cycle_X)\n",
    "        loss_cycle_Y = cycle_loss_func(real_Y, cycle_Y)\n",
    "\n",
    "        # Identity loss \n",
    "        identity_X = generate_YtoX(real_X)\n",
    "        identity_Y = generate_XtoY(real_Y)\n",
    "        loss_identity_X = identity_loss_func(real_X, identity_X)\n",
    "        loss_identity_Y = identity_loss_func(real_Y, identity_Y)\n",
    "\n",
    "        #total generator loss\n",
    "        total_loss_generator = (\n",
    "            loss_G_XtoY + loss_G_YtoX + 10 * (loss_cycle_X + loss_cycle_Y) + 5 * (loss_identity_X + loss_identity_Y)\n",
    "        )\n",
    "\n",
    "        # Train discriminators\n",
    "        optimizer_discriminator_X.zero_grad()\n",
    "        optimizer_discriminator_Y.zero_grad()\n",
    "\n",
    "        # Discriminator X loss\n",
    "        loss_discriminator_X_real = adversarial_loss_func(Discriminator_X(real_X), torch.ones_like(Discriminator_X(real_X)))\n",
    "        loss_discriminator_X_fake = adversarial_loss_func(Discriminator_X(fake_X.detach()), torch.zeros_like(Discriminator_X(fake_X)))\n",
    "        loss_discriminator_X = (loss_discriminator_X_real + loss_discriminator_X_fake) / 2\n",
    "        loss_discriminator_X.backward()\n",
    "        optimizer_discriminator_X\n",
    "\n",
    "        #Discriminator Y loss\n",
    "        loss_discriminator_Y_real = adversarial_loss_func(Discriminator_Y(real_Y), torch.ones_like(Discriminator_Y(real_Y)))\n",
    "        loss_discriminator_Y_fake = adversarial_loss_func(Discriminator_Y(fake_Y.detach()), torch.zeros_like(Discriminator_Y(fake_Y)))\n",
    "        loss_discriminator_Y = (loss_discriminator_Y_real + loss_discriminator_Y_fake) / 2\n",
    "        loss_discriminator_Y.backward()\n",
    "        optimizer_discriminator_Y.step()\n",
    "    \n",
    "    return total_loss_generator, loss_discriminator_X, loss_discriminator_Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_cyclegan(generate_XtoY, generate_YtoX, Discriminator_X, Discriminator_Y, validation_loader, device):\n",
    "    generate_XtoY.eval()\n",
    "    generate_YtoX.eval()\n",
    "    Discriminator_X.eval()\n",
    "    Discriminator_Y.eval()\n",
    "\n",
    "    total_generator_loss = 0.0\n",
    "    total_discriminator_X_loss = 0.0\n",
    "    total_discriminator_Y_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for real_X, real_Y in tqdm(validation_loader, desc='Validation'):\n",
    "            real_X, real_Y = real_X.to(device), real_Y.to(device)\n",
    "\n",
    "            # Generator Forward Pass\n",
    "            fake_Y = generate_XtoY(real_X)\n",
    "            fake_X = generate_YtoX(real_Y)\n",
    "            cycle_X = generate_YtoX(fake_Y)\n",
    "            cycle_Y = generate_XtoY(fake_X)\n",
    "\n",
    "            # Adversarial Loss \n",
    "            loss_G_XtoY = adversarial_loss(Discriminator_Y(fake_Y), torch.ones_like(Discriminator_Y(fake_Y))) #how well generator fools discriminator\n",
    "            loss_G_YtoX = adversarial_loss(Discriminator_X(fake_X), torch.ones_like(Discriminator_X(fake_X)))\n",
    "\n",
    "            # Cycle consistency loss\n",
    "            loss_cycle_X = cycle_loss_func(real_X, cycle_X)\n",
    "            loss_cycle_Y = cycle_loss_func(real_Y, cycle_Y)\n",
    "\n",
    "            # Identity loss\n",
    "            identity_X = generate_YtoX(real_X)\n",
    "            identity_Y = generate_XtoY(real_Y)\n",
    "            loss_identity_X = identity_loss_func(real_X, identity_X)\n",
    "            loss_identity_Y = identity_loss_func(real_Y, identity_Y)\n",
    "\n",
    "            # Total generator loss \n",
    "            loss_generator = (\n",
    "                loss_G_XtoY + loss_G_YtoX + \n",
    "                10 * (loss_cycle_X + loss_cycle_Y) +\n",
    "                5 * (loss_identity_X + loss_identity_Y)\n",
    "            )\n",
    "\n",
    "            # Discrimnator loss\n",
    "            loss_discriminator_X_real = adversarial_loss_func(Discriminator_X(real_X), torch.ones_like(Discriminator_X(real_X)))\n",
    "            loss_discriminator_X_fake = adversarial_loss_func(Discriminator_X(fake_X), torch.zeros_like(Discriminator_X(fake_X)))\n",
    "            loss_discriminator_X = (loss_discriminator_X_real + loss_discriminator_X_fake) / 2  \n",
    "\n",
    "            loss_discriminator_Y_real = adversarial_loss_func(Discriminator_Y(real_Y), torch.ones_like(Discriminator_Y(real_Y)))\n",
    "            loss_discriminator_Y_fake = adversarial_loss_func(Discriminator_Y(fake_Y), torch.zeros_like(Discriminator_Y(fake_Y)))\n",
    "            loss_discriminator_Y = (loss_discriminator_Y_real + loss_discriminator_Y_fake) / 2\n",
    "\n",
    "            # accumulate losses\n",
    "            total_generator_loss += loss_generator.item()\n",
    "            total_discriminator_X_loss += loss_discriminator_X.item()\n",
    "            total_discriminator_Y_loss += loss_discriminator_Y.item()   \n",
    "    average_generator_loss = total_generator_loss / len(validation_loader)\n",
    "    average_discriminator_X_loss = total_discriminator_X_loss / len(validation_loader)\n",
    "    average_discriminator_Y_loss = total_discriminator_Y_loss / len(validation_loader)\n",
    "\n",
    "    return average_generator_loss, average_discriminator_X_loss, average_discriminator_Y_loss\n",
    "\n",
    "def visualize_metrics(train_generator_losses, val_generator_losses, \n",
    "                      train_discriminator_X_losses, val_discriminator_X_losses,\n",
    "                      train_discriminator_Y_losses, val_discriminator_Y_losses):\n",
    "    \n",
    "    # Plot for generator loss\n",
    "    plt.figure()\n",
    "    plt.plot(train_generator_losses, label='Train Generator Loss')\n",
    "    plt.plot(val_generator_losses, label='Validation Generator Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Generator loss over Epochs')\n",
    "    plt.savefig('generator_loss.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot for discriminator X loss\n",
    "    plt.figure()\n",
    "    plt.plot(train_discriminator_X_losses, label='Train Discriminator X Loss')\n",
    "    plt.plot(val_discriminator_X_losses, label='Validation Discriminator X Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Discriminator X loss over Epochs')\n",
    "    plt.savefig('discriminator_X_loss.png')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot for discriminator Y loss\n",
    "    plt.figure()\n",
    "    plt.plot(train_discriminator_Y_losses, label='Train Discriminator Y Loss')\n",
    "    plt.plot(val_discriminator_Y_losses, label='Validation Discriminator Y Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')      \n",
    "    plt.legend()\n",
    "    plt.title('Discriminator Y loss over Epochs')\n",
    "    plt.savefig('discriminator_Y_loss.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main loop func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    best_val_generator_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    best_epoch = 0\n",
    "\n",
    "    # tracking loss lists\n",
    "    train_generator_losses, val_generator_losses = [], []\n",
    "    train_discriminator_X_losses, val_discriminator_X_losses = [], []\n",
    "    train_discriminator_Y_losses, val_discriminator_Y_losses = [], []\n",
    "\n",
    "    with open(\"cyclegan_training_log.txt\", \"w\") as f:\n",
    "        f.write(\"Epoch, Train Generator Loss, Val Generator Loss, Train Discriminator X Loss, Val Discriminator X Loss, Train Discriminator Y Loss, Val Discriminator Y Loss\\n\")\n",
    "\n",
    "        # Main training loop\n",
    "        for epoch in range(epochs):\n",
    "            print(f'Epoch {epoch + 1}/{epochs}')\n",
    "            \n",
    "            train_generator_loss, train_discriminator_X_loss, train_discriminator_Y_loss = train_cyclegan(\n",
    "                train_loader = train_loader,\n",
    "                generate_XtoY = generate_XtoY,\n",
    "                generate_YtoX = generate_YtoX,\n",
    "                Discriminator_X = Discriminator_X,\n",
    "                Discriminator_Y = Discriminator_Y,\n",
    "                device = device\n",
    "            )\n",
    "\n",
    "            validate_generator_loss, validate_discriminator_X_loss, validate_discriminator_Y_loss = validate_cyclegan(\n",
    "                generate_XtoY = generate_XtoY,\n",
    "                generate_YtoX = generate_YtoX,\n",
    "                Discriminator_X = Discriminator_X,\n",
    "                Discriminator_Y = Discriminator_Y,\n",
    "                validation_loader = validation_loader,\n",
    "                device = device\n",
    "            )\n",
    "\n",
    "            # log losses\n",
    "            train_generator_losses.append(train_generator_loss)\n",
    "            val_generator_losses.append(validate_generator_loss)\n",
    "            train_discriminator_X_losses.append(train_discriminator_X_loss)\n",
    "            val_discriminator_X_losses.append(validate_discriminator_X_loss)\n",
    "            train_discriminator_Y_losses.append(train_discriminator_Y_loss)\n",
    "            val_discriminator_Y_losses.append(validate_discriminator_Y_loss)\n",
    "\n",
    "            f.write(f\"{epoch + 1}, {train_generator_loss:.4f}, {validate_generator_loss:.4f},\"\n",
    "                     f\"{train_discriminator_X_loss:.4f}, {validate_discriminator_X_loss:.4f},\"\n",
    "                     f\"{train_discriminator_Y_loss:.4f}, {validate_discriminator_Y_loss:.4f}\\n\")\n",
    "            \n",
    "            print(f\"[Epoch {epoch + 1}]\")\n",
    "            print(f\"Generator loss: Train = {train_generator_loss:.4f}, Validation = {validate_generator_loss:.4f}\")\n",
    "            print(f\"Discriminator X loss: Train = {train_discriminator_X_loss:.4f}, Validation = {validate_discriminator_X_loss:.4f}\")\n",
    "            print(f\"Discriminator Y loss: Train = {train_discriminator_Y_loss:.4f}, Validation = {validate_discriminator_Y_loss:.4f}\")\n",
    "           \n",
    "            # save best model\n",
    "            if validate_generator_loss < best_val_generator_loss:\n",
    "                best_val_generator_loss = validate_generator_loss\n",
    "                best_epoch = epoch + 1\n",
    "                best_model_state = {\n",
    "                   'Generator_XtoY': generate_XtoY.state_dict(),\n",
    "                   'Generator_YtoX': generate_YtoX.state_dict(),\n",
    "                   'Discriminator_X': Discriminator_X.state_dict(),\n",
    "                   'Discriminator_Y': Discriminator_Y.state_dict(),\n",
    "                }\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        torch.save(best_model_state, 'best_cyclegan_model.pth')\n",
    "        print(f\"Best model saved at epoch {best_epoch} with validation generator loss {best_val_generator_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # visualise loss curves\n",
    "    visualize_metrics(train_generator_losses, val_generator_losses, \n",
    "                      train_discriminator_X_losses, val_discriminator_X_losses,\n",
    "                      train_discriminator_Y_losses, val_discriminator_Y_losses)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.freeze_support()\n",
    "    # Main training loop\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (279424823.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    from cyclegan import *CycleGan* # model.py\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "    # running_loss1 = 0.0 #adversariel (main)\n",
    "    # running_loss2 = 0.0 #cycle consistency\n",
    "    # running_loss3 = 0.0 #identity\n",
    "    # true_labels = []\n",
    "    # pred_labels = []\n",
    "    # train_losses1 = []\n",
    "    # train_losses2 = []\n",
    "    # train_losses3 = []\n",
    "    # for batch_idx, (inputs, targets) in enumerate(tqdm(trainloader, desc=\"Training\")):\n",
    "    #     inputs, targets = inputs.to(device), targets.to(device)\n",
    "    #     optimizer.zero_grad()  # Clear gradients\n",
    "    #         # Forward pass\n",
    "    #         outputs = model(inputs)\n",
    "    #         loss1 = criterion1(outputs, targets)\n",
    "    #         loss2 = criterion2(outputs, targets)\n",
    "    #         loss3 = criterion3(outputs, targets)\n",
    "\n",
    "    #         # Backward pass\n",
    "    #         loss1.backward()\n",
    "    #         optimizer.step()\n",
    "\n",
    "    #         # Update loss\n",
    "    #         running_loss1 += loss1.item()\n",
    "    #         running_loss2 += loss2.item()\n",
    "    #         running_loss3 += loss3.item()\n",
    "\n",
    "    #         # Collect predictions and true labels for accuracy calculation\n",
    "    #         _, predicted = outputs.max(1)\n",
    "    #         pred_labels.extend(predicted.cpu().numpy())\n",
    "    #         true_labels.extend(targets.cpu().numpy())\n",
    "\n",
    "    # avg_loss1 = running_loss1 / len(trainloader)\n",
    "    # avg_loss2 = running_loss2 / len(trainloader)\n",
    "    # avg_loss3 = running_loss3 / len(trainloader)\n",
    "\n",
    "    # train_losses1.append(avg_loss1)\n",
    "    # train_losses2.append(avg_loss2)\n",
    "    # train_losses3.append(avg_loss3)\n",
    "\n",
    "    # return train_losses1, train_losses2, train_losses3\n",
    "\n",
    "# Validation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
